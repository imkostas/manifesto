1. 1.	Design designs design.
1.1 Designing is ontological designing: designing implies designing the very conditions of human existence. But, if this is true, then design designs design. We are designing AI tools that will carry out the task of designing (a different point of view).
    2. 1.2	Adaptation must be framed in the context of the relation between human and artificial.
    3. 1.3	Designers as facilitators of the integration between human and artificial (intelligence).
1.3.1 Designing is surviving in a damaged planet (Donna Haraway). It is an imagination effort.
1.3.2 The task of the designer is to imagine alternatives rather than to solve problems.
1.3.2.1 The designer should be the voice of the disorder beneath the constructed order (imagining possible worlds alternatives to the present world).
1.3.3 The Anthropocene Era cannot be carried out in a sustainable way. AI can help.
1.3.3.1 AI and Environmental Design: Anything to say?
1.3.3.2 AI and Industrial Design: Anything to say?
1.4 Matters of fact are matters of concerns.
1.4.1 We need a “democracy of objects”, against any narcissistic anthropocentric view of the world.
1.4.1.1 We must respect rubbish as much as we must respect humans.
1.5 Anything new is unknown until it is discovered.
1.5.1 Design is to remember what we already know but forgot (Plato).
1.6 Analogical reasoning as complementary, or supplementary (this is a decision point), to digital reasoning. Digital reasoning as complementary, or supplementary (this is a decision point), to analogical reasoning.
1.7 Why does creation have to involve only humans?
1.7.1 A 'genius' is nothing but a social construct.
1.7.2 Designing is not the activity of a sort of ‘genius’. AI is the ‘party-pooper’.
1.7.2.1 What is behind the Turing Test? Just the Turing Test or the output of a social construct? (Remind that Alan Turing was homosexual).
1.7.3 Unbeknownst to the designer, there is a computer programmer that creates, controls, and manipulates the ideas that the designer has.

    8. 2	Algorithms can make algorithms that can make algorithms that can make algorithms, and so on.
2.1 A deterministic machine can produce a non-deterministic behavior.
2.1.1 A computer is not human and, therefore, cannot think, let alone be a genius. But it can behave like one (Turing Test).
2.2 AI is only human but at the same time AI is not human.
2.2.1 Weak-AI is strong enough. Design is not interested in Strong-AI (AGI).
2.2.2 AI or IA? Artificial Intelligence (Simon) or Intelligence Amplification (Ashby)? Or both? Or a useless dilemma?
2.3 Do we understand AI? Does AI understand us?
2.3.1 Computation is not the same as computerization. Most designers cannot tell the difference.
2.3.2 Autonomous is not automated which is not automatic. Most designers cannot tell the difference.
2.3.3 AI is already deciding about our lives and the lives of our families. We do not recognize it.
2.3.4 Is AI a risk for our societies, in the sense of Musk or Kurzweil? If not, where is the risk?
2.4 Designing AI for solving problems. Finding problems for designing AI.
2.5 AI, for what? Machine Learning, to whom? Self-driving cars, to where? They are all design problems.
2.6 We cannot escape from the demand of an AI curriculum dedicated to design students.
2.6.1 Code is the passport to the alien country of AI.
2.7 AI has added a second-order complexity to the general complexity of human societies by introducing one more actor on the top of the intricate web of human affairs. This is a design problem
2.7.1 AI is intrinsically and extrinsically opaque. Are these design problems?
2.7.2 Data are never neutral, correlation is not causation, prediction is not anticipation (against Chris Anderson and Big Data). Do designers recognize it? Do they have something to say?
2.7.2.1 AI embeds biases as much as humans embed biases; the only difference is that AI amplifies and increases those biases.
2.7.2.2 List the main human biases and identify them in AI applications currently in use. Then come back to us and discuss a potential solution to them. Does this question raise a design task?
2.7.3 AI systems can learn in ways which are unpredictable or immediately incomprehensible to their own creators. The dialog with the machine is called randomness.
2.7.4 What is the difference between responsibility and autonomy? Floridi’s ‘decide-to-delegate’ model is not an answer.
2.7.5 Is not Baidu Search AI? Is not Google Maps AI? Is not Amazon Recommendation Engine AI? Is not Didi AI? Is not TikTok AI?
2.7.6 Thinking follows AI.
2.7.7 We need a new job role: AI Product Designers.
    8. 2.8	Who is the creator of an AI work of art?
        1. 2.8.1	AI art: real or fake creativity?
        2. 2.8.2	The intricacies relating creativity power and combinatorial power.
        3. 2.8.3	Judging AI creativity is like measuring a segment whose length is constantly changing by using a meter.

        1. 3.	Humans invent themselves by inventing: hominization is technicization. If we believe it, then we need a responsible innovation.
    1. 3.1	Each technology has its own Gestell, the en-framing, the lenses according to which it looks at the reality (Heidegger).
3.1.1 What is the AI Gestell? Shall designers be concerned about the Gestell behind biotechnology, or neuro-engineering, or geo-engineering as well?
3.2 Innovation must be socially governed.
3.2.1 Responsible innovation for the human good. How can design contribute?
3.2.2 Innovation cannot be conceived ‘in vitro’, exactly as algorithms do not live ‘no-where’.
3.2.3 Risks, vulnerabilities, emergencies become increasingly socialized: risk is what society is allowed to perceive as a risk. 
3.3 Responsible innovation as anticipation, self-awareness, inclusivity, responsiveness.
3.3.1 Anticipation as asking “what-if” questions since the very beginning of the innovation process (as contrasted to post hoc interventions).
3.3.2 Reflexivity as being aware that innovation is always situated into a particular context within limited cognitive resources.
3.3.3 Inclusivity as democratically engaging the many actors which should be involved into the narrative.
3.3.4 Responsiveness as the capacity to shape and re-shape directions in response to challenging circumstances.
3.4 Any (digital) technology embeds a ‘form-of life’ in the Agamben’s sense.
3.4.1 Looking inside the technological box vs. looking across the technological box: design tasks in any case, design tasks for any responsible designer.
3.4.2 Looking across the AI box means to assess how it fits the form-of-life our societies wish to achieve.
3.4.3 Self-driving cars, for what and to where? Do we know them enough? Are they safe enough? Who is accountable? Is there any alternative? What is the picture behind this technology? What is the representation of the city landscape behind this picture? Do we wish to discuss it?
3.4.4 Smart objects could be ‘AI for the good’. But Smart Objects are not tools. Towards a ‘Smart City’.

    1. 4.	All that is solid is melting down. What is the role of design in a vanishing world? Should designers consider all this?
4.1 The vanishing of the Cartesian dualism. Mind becomes just a brain. Body becomes just a prosthesis. Brain itself gets modularized. Finally, the Self vanishes out, consciousness becomes an epiphenomenon, and all that is solid is melting down.
4.3 The vanishing of the Newtonian world. Simultaneity and locality become relative. Space-time evolves, the universe expands or contracts. Objects become tendencies to exist, knots of strings and nets. Fundamental forces become emergent. The Holographic Principle (Gerad’t Hooft, Leonard Susskind) as the 2D informational limit of the 3D world.
4.4 The vanishing of ‘the method’ (mathematics). Russel’s paradox, Godel’s incompleteness theorems, Church-Turing Thesis as cognitive loops.
4.4.1 Loops generate paradoxes. What was conceived for proving the limits of any formalist approach (Turing’s abstract machine, Godel’s incompleteness theorems, Church-Turing thesis) becomes the triumph of the formalist approach. This is one among many of the strange loops of our age. Does AI participate in this loop?
4.5 Humans are rational animals, said Aristotle. But, if rationality, intelligence, is the ‘specific difference’ that makes the difference with other animals, now what made humans unique is vanishing as well. Why should we not conceive other forms of intelligence, beside ours?
4.6 The computational metaphor, with the corresponding datafication process, is the ideologically dominant metaphysics of this century (physics, biology, genetics, neurosciences, psychology).
4.6.1 The computational metaphor embeds three assumptions: a) a dematerialization of work, with the goal of speeding up the process of space/time compression necessary to the distribution and consumption of the goods; b) a process of disembodiment inducing the destruction of social spaces of direct, immediate interaction, with the consequent fragmentation of the relational affectivity of the workers; c) a de-subjectivation of the individual corresponding to a process of datafication appropriate to transform the worker into the product itself.
4.6.2 These assumptions are the ideological counterpart of the late capitalist mode of accumulation. All this is called ‘cognitive capitalism’.
4.6.3 Cognitive capitalism means experiences, feelings, emotions becoming commodities.
4.6.4 Imagine a world where everything is done by machines. What if capitalism
should be accelerated instead of overcome in order to generate radical social change. This theory is called ‘accelerationism’ (Nick Srnicek).
4.7 Can AI be used by capitalism to continue to exploit in even more sophisticated ways? If the answer is yes, then can AI be used by non-capitalist countries to prevent, avoid, or reduce exploitation?
4.8 Who is fixing the AI goals? Who is fixing the technology goals? Structures of power vs. power of structures.
